{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-nearest neighbors\n",
    "\n",
    "This dataset was obtained from https://archive.ics.uci.edu/ml/datasets/Heart+Disease (this is a great resource for datasets to try machine learning on). It has data on patients that are and are not diagnosed with heart disease.\n",
    "\n",
    "The attributes are:\n",
    "* age: age in years \n",
    "* sex: sex (1 = male; 0 = female) \n",
    "* cp: chest pain type \n",
    " * -- Value 1: typical angina \n",
    " * -- Value 2: atypical angina \n",
    " * -- Value 3: non-anginal pain \n",
    " * -- Value 4: asymptomatic \n",
    "* trestbps: resting blood pressure (in mm Hg on admission to the hospital) \n",
    "* chol: serum cholestoral in mg/dl \n",
    "* fbs: (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false) \n",
    "* restecg: resting electrocardiographic results \n",
    " * -- Value 0: normal \n",
    " * -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV) \n",
    " * -- Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria \n",
    "* thalach: maximum heart rate achieved \n",
    "* exang: exercise induced angina (1 = yes; 0 = no) \n",
    "* oldpeak = ST depression induced by exercise relative to rest \n",
    "* slope: the slope of the peak exercise ST segment \n",
    " * -- Value 1: upsloping \n",
    " * -- Value 2: flat \n",
    " * -- Value 3: downsloping \n",
    "* ca: number of major vessels (0-3) colored by flourosopy \n",
    "* thal: 3 = normal; 6 = fixed defect; 7 = reversable defect \n",
    "* num: diagnosis of heart disease (angiographic disease status) \n",
    " * -- Value 0: absence.\n",
    " * -- Value 1,2,3,4: presence of heart disease\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the data\n",
    "\n",
    "Read in the data, modify the dependent variable name and plot a histogram of the ages of patients, both healthy and those with heart disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "\n",
       "   slope   ca thal  disease  \n",
       "0    3.0  0.0  6.0        0  \n",
       "1    2.0  3.0  3.0        1  \n",
       "2    2.0  2.0  7.0        1  \n",
       "3    3.0  0.0  3.0        0  \n",
       "4    1.0  0.0  3.0        0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('cleveland.csv')\n",
    "\n",
    "# Collapse all values 1-4 into a single value so that \"num\" is boolean\n",
    "df = df.rename({'num':'disease'}, axis=1)\n",
    "df['disease'] = df.disease.apply(lambda x: min(x, 1))\n",
    "df.drop(df[df['thal'] == '?'].index, inplace=True)\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multiple dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knnPredict(data, attributes, numOfNeighbors, target='disease'):\n",
    "    nn = NearestNeighbors(n_neighbors=numOfNeighbors, metric='euclidean', algorithm='auto')\n",
    "    \n",
    "    # Standardize\n",
    "    newAttributes = []\n",
    "    for attribute in attributes:\n",
    "        standard = data[attribute]-data[attribute].mean()/data[attribute].std()\n",
    "        standard.name = standard.name+'_s'\n",
    "        newAttributes.append(standard.name)\n",
    "        data = pd.concat([data,standard],axis=1)\n",
    "        \n",
    "    # Build underlying structure with standardized data   \n",
    "    X = data[newAttributes].values\n",
    "    y = data[target].values\n",
    "    fit = nn.fit(X)\n",
    "    \n",
    "    # Choose a random patient\n",
    "    i = random.randint(0,len(X)-1)\n",
    "    patientX = X[i]\n",
    "    patienty = y[i]\n",
    "    # display('Our patient',data.iloc[i])\n",
    "    \n",
    "    # Find the k nearest neighbors, not including self\n",
    "    distances, indices = fit.kneighbors([patientX],numOfNeighbors+1)\n",
    "    nbrs = data.iloc[indices[0]]\n",
    "    # Delete self from data\n",
    "    nbrs = nbrs.drop(data.iloc[i].name)\n",
    "    # display(nbrs)\n",
    "    \n",
    "    # Count the number of neighbors that have target\n",
    "    have = nbrs[nbrs[target] == 0].count()[target]\n",
    "    # Count the number of neighbors that DON'T have target\n",
    "    dontHave = nbrs[nbrs[target] == 1].count()[target]\n",
    "    # print('Have: {}\\ndontHave: {}'.format(have, dontHave))\n",
    "    \n",
    "    # Predict that our random patient is like the majority of its neighbors\n",
    "    predict = 0 if (dontHave > have) else 1\n",
    "    # According to the records, did our patient have the target\n",
    "    actual = 0 if (patienty == 0) else 1\n",
    "    success = predict == actual\n",
    "    # print('Sucess:',success)\n",
    "    return success, patienty == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testMeSenpai(data, attributes, numOfNeighbors, numOfTests=1, target='disease'):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for test in range(numOfTests):\n",
    "        yPred, yAct = knnPredict(data, attributes, numOfNeighbors)\n",
    "        y_pred.append(yPred)\n",
    "        y_true.append(yAct)\n",
    "    return y_pred ,y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33333333 0.        ] [0.33333333 0.        ] [0.33333333 0.        ] [3 2] \n",
      "\n",
      "[0.33333333 0.5       ] [0.5        0.33333333] [0.4 0.4] [2 3] \n",
      "\n",
      "[0.5 1. ] [1.         0.33333333] [0.66666667 0.5       ] [2 3] \n",
      "\n",
      "[0.6 0. ] [1. 0.] [0.75 0.  ] [3 2] \n",
      "\n",
      "[1.         0.66666667] [0.66666667 1.        ] [0.8 0.8] [3 2] \n",
      "\n",
      "[0.75 1.  ] [1.  0.5] [0.85714286 0.66666667] [3 2] \n",
      "\n",
      "[0.5        0.66666667] [0.5        0.66666667] [0.5        0.66666667] [2 3] \n",
      "\n",
      "[0.33333333 0.        ] [0.33333333 0.        ] [0.33333333 0.        ] [3 2] \n",
      "\n",
      "[0. 1.] [0.  0.6] [0.   0.75] [0 5] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def crossValidate(data, attributes, numOfNeighbors, numOfTests, target='disease', level = 10):\n",
    "    folds = []\n",
    "    for i in range(level):\n",
    "        folds.append(data.sample(frac = 1/level))\n",
    "        \n",
    "    # Train missing one fold\n",
    "    for i in range(level-1):\n",
    "        temp = pd.concat([data,folds[i]])\n",
    "        temp = temp.drop_duplicates(keep=False)\n",
    "        \n",
    "        y_pred,y_true = testMeSenpai(temp, attributes, numOfNeighbors, numOfTests, target='disease')\n",
    "        (p,r,f,s) = precision_recall_fscore_support(y_pred,y_true,zero_division=0)\n",
    "        print(p,r,f,s,'\\n')\n",
    "        \n",
    "df1 = df.copy()\n",
    "k = 5\n",
    "numOfTests = 5\n",
    "attributes = ['age','trestbps']\n",
    "\n",
    "crossValidate(df1,attributes,k,numOfTests)\n",
    "# y_pred, y_true = testMeSenpai(df1,attributes,k,numOfTests)\n",
    "# (p,r,f,s) = precision_recall_fscore_support(y_pred,y_true)\n",
    "# display(p,r,f,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testAgainstTest(testData,attributes,k):\n",
    "    y_pred, y_true = testMeSenpai(testData,attributes,k)\n",
    "    (p,r,f,s) = precision_recall_fscore_support(y_pred,y_true)\n",
    "    return p,r,f,s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is the value of k (nearest neigbors) and set of attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day of the challenge set, all we need to do is change this file name and run it\n",
    "new_df = pd.read_csv('cleveland-test-sample.csv')\n",
    "\n",
    "# Collapse all values 1-4 into a single value so that \"num\" is boolean\n",
    "new_df = new_df.rename({'num':'disease','Unnamed: 0':'id'}, axis=1)\n",
    "new_df['disease'] = new_df.disease.apply(lambda x: min(x, 1))\n",
    "\n",
    "# Build a bigger data set to \n",
    "temp = pd.concat([df,new_df]).reset_index()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chosen features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "chosen_features = ['cp', 'trestbps', 'chol', 'restecg', 'thalach', 'exang', 'thal', 'age']\n",
    "numFeatures = 5\n",
    "attributes = ['age','trestbps','chol', 'thalach']\n",
    "# standardizing noncatagorical data\n",
    "newAttributes = []\n",
    "data1 = df.copy()\n",
    "for attribute in attributes:\n",
    "    standard = (data1[attribute]-data1[attribute].mean())/data1[attribute].std()\n",
    "    chosen_features.remove(standard.name)\n",
    "    chosen_features.append(standard.name+'_s')\n",
    "    standard.name = standard.name+'_s'\n",
    "    newAttributes.append(standard.name)\n",
    "    data1 = pd.concat([data1,standard],axis=1)\n",
    "    data1.drop(attribute,axis=1,inplace=True)\n",
    "featureslist = list(itertools.combinations(chosen_features,numFeatures))\n",
    "featureslist = [list(x) for x in featureslist]\n",
    "data1['thal'] = data1['thal'].str.replace('.0','',regex=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## monte carlo data split with selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make split for one monte carlo cross validation run\n",
    "def monteCarloCVSplit(data, level = 10):\n",
    "    CVtest = data.sample(frac = 1/level)\n",
    "    CVtrain = data.drop(CVtest.index)\n",
    "    return CVtrain, CVtest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run knn on given attributes and CV split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knnPredictions(CVtrain, CVTest, attributes, numOfNeighbors, target='disease'):\n",
    "    nn = NearestNeighbors(n_neighbors=numOfNeighbors, metric='euclidean', algorithm='auto')\n",
    "    \n",
    "    # Build underlying structure with standardized data   \n",
    "    X = CVtrain[attributes].values\n",
    "    y = CVtrain[target].values\n",
    "    testX = CVTest[attributes].values\n",
    "    testy = CVTest[target].values\n",
    "    display(X)\n",
    "    fit = nn.fit(X)\n",
    "\n",
    "    distances, indices = fit.kneighbors(testX, n_neighbors = numOfNeighbors)\n",
    "    print(indices)\n",
    "    \n",
    "    # # Count the number of neighbors that have target\n",
    "    # have = nbrs[nbrs[target] == 0].count()[target]\n",
    "    # # Count the number of neighbors that DON'T have target\n",
    "    # dontHave = nbrs[nbrs[target] == 1].count()[target]\n",
    "    # # print('Have: {}\\ndontHave: {}'.format(have, dontHave))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0, 2.0, 0.0, '6', 0.9427516619612377],\n",
       "       [4.0, 2.0, 1.0, '3', 1.3838993498746968],\n",
       "       [3.0, 0.0, 0.0, '3', -1.9247083094762452],\n",
       "       ...,\n",
       "       [4.0, 0.0, 1.0, '7', 0.2810301300910494],\n",
       "       [2.0, 2.0, 0.0, '3', 0.2810301300910494],\n",
       "       [3.0, 0.0, 0.0, '3', -1.8144213874978805]], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[220  56 223 218  29]\n",
      " [106  79 104  36  85]\n",
      " [169 114 191 214 217]\n",
      " [122  77 225 202  44]\n",
      " [230 255  13 142  11]\n",
      " [ 44 202  50 194 122]\n",
      " [268 153 248 265  93]\n",
      " [ 65  88 134  87 176]\n",
      " [171   1 136 234  78]\n",
      " [249 128  14  81 231]\n",
      " [ 99  80 141 177 126]\n",
      " [217 191 242 114 169]\n",
      " [261 103 239  97  57]\n",
      " [  8 269 247  18  67]\n",
      " [ 18 247 269   8 221]\n",
      " [ 96 237 241 235 178]\n",
      " [262 197 183 151   5]\n",
      " [214 199  24 226 146]\n",
      " [257 259 182  73  86]\n",
      " [ 43 245  82 170  58]\n",
      " [152 160   4 192 145]\n",
      " [188   0 124 159 164]\n",
      " [ 32 168 179  25 105]\n",
      " [ 64 240 264 104  36]\n",
      " [ 14 128 249 166  21]\n",
      " [  8 269  51 247  18]\n",
      " [ 27  93  95  63 248]\n",
      " [209 156  42  25  32]\n",
      " [214 199 169 114 144]\n",
      " [258 165  40  19  72]]\n"
     ]
    }
   ],
   "source": [
    "CVtrain1, CVtest1 = monteCarloCVSplit(data1)\n",
    "\n",
    "knnPredictions(CVtrain1, CVtest1, featureslist[0] , 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "8112dd241fa2daf28d9e3e7428f74cc036918cdd417492de7d9a77b623e05e74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
