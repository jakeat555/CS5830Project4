{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-nearest neighbors\n",
    "\n",
    "This dataset was obtained from https://archive.ics.uci.edu/ml/datasets/Heart+Disease (this is a great resource for datasets to try machine learning on). It has data on patients that are and are not diagnosed with heart disease.\n",
    "\n",
    "The attributes are:\n",
    "* age: age in years \n",
    "* sex: sex (1 = male; 0 = female) \n",
    "* cp: chest pain type \n",
    " * -- Value 1: typical angina \n",
    " * -- Value 2: atypical angina \n",
    " * -- Value 3: non-anginal pain \n",
    " * -- Value 4: asymptomatic \n",
    "* trestbps: resting blood pressure (in mm Hg on admission to the hospital) \n",
    "* chol: serum cholestoral in mg/dl \n",
    "* fbs: (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false) \n",
    "* restecg: resting electrocardiographic results \n",
    " * -- Value 0: normal \n",
    " * -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV) \n",
    " * -- Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria \n",
    "* thalach: maximum heart rate achieved \n",
    "* exang: exercise induced angina (1 = yes; 0 = no) \n",
    "* oldpeak = ST depression induced by exercise relative to rest \n",
    "* slope: the slope of the peak exercise ST segment \n",
    " * -- Value 1: upsloping \n",
    " * -- Value 2: flat \n",
    " * -- Value 3: downsloping \n",
    "* ca: number of major vessels (0-3) colored by flourosopy \n",
    "* thal: 3 = normal; 6 = fixed defect; 7 = reversable defect \n",
    "* num: diagnosis of heart disease (angiographic disease status) \n",
    " * -- Value 0: absence.\n",
    " * -- Value 1,2,3,4: presence of heart disease\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the data\n",
    "\n",
    "Read in the data, modify the dependent variable name and plot a histogram of the ages of patients, both healthy and those with heart disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "\n",
       "   slope   ca thal  disease  \n",
       "0    3.0  0.0  6.0        0  \n",
       "1    2.0  3.0  3.0        1  \n",
       "2    2.0  2.0  7.0        1  \n",
       "3    3.0  0.0  3.0        0  \n",
       "4    1.0  0.0  3.0        0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('cleveland.csv')\n",
    "\n",
    "# Collapse all values 1-4 into a single value so that \"num\" is boolean\n",
    "df = df.rename({'num':'disease'}, axis=1)\n",
    "df['disease'] = df.disease.apply(lambda x: min(x, 1))\n",
    "df.drop(df[df['thal'] == '?'].index, inplace=True)\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multiple dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knnPredict(data, attributes, numOfNeighbors, target='disease'):\n",
    "    nn = NearestNeighbors(n_neighbors=numOfNeighbors, metric='euclidean', algorithm='auto')\n",
    "    \n",
    "    # Standardize\n",
    "    newAttributes = []\n",
    "    for attribute in attributes:\n",
    "        standard = data[attribute]-data[attribute].mean()/data[attribute].std()\n",
    "        standard.name = standard.name+'_s'\n",
    "        newAttributes.append(standard.name)\n",
    "        data = pd.concat([data,standard],axis=1)\n",
    "        \n",
    "    # Build underlying structure with standardized data   \n",
    "    X = data[newAttributes].values\n",
    "    y = data[target].values\n",
    "    fit = nn.fit(X)\n",
    "    \n",
    "    # Choose a random patient\n",
    "    i = random.randint(0,len(X)-1)\n",
    "    patientX = X[i]\n",
    "    patienty = y[i]\n",
    "    # display('Our patient',data.iloc[i])\n",
    "    \n",
    "    # Find the k nearest neighbors, not including self\n",
    "    distances, indices = fit.kneighbors([patientX],numOfNeighbors+1)\n",
    "    nbrs = data.iloc[indices[0]]\n",
    "    # Delete self from data\n",
    "    nbrs = nbrs.drop(data.iloc[i].name)\n",
    "    # display(nbrs)\n",
    "    \n",
    "    # Count the number of neighbors that have target\n",
    "    have = nbrs[nbrs[target] == 0].count()[target]\n",
    "    # Count the number of neighbors that DON'T have target\n",
    "    dontHave = nbrs[nbrs[target] == 1].count()[target]\n",
    "    # print('Have: {}\\ndontHave: {}'.format(have, dontHave))\n",
    "    \n",
    "    # Predict that our random patient is like the majority of its neighbors\n",
    "    predict = 0 if (dontHave > have) else 1\n",
    "    # According to the records, did our patient have the target\n",
    "    actual = 0 if (patienty == 0) else 1\n",
    "    success = predict == actual\n",
    "    # print('Sucess:',success)\n",
    "    return success, patienty == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testMeSenpai(data, attributes, numOfNeighbors, numOfTests=1, target='disease'):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for test in range(numOfTests):\n",
    "        yPred, yAct = knnPredict(data, attributes, numOfNeighbors)\n",
    "        y_pred.append(yPred)\n",
    "        y_true.append(yAct)\n",
    "    return y_pred ,y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0. ] [0.25 0.  ] [0.33333333 0.        ] [4 1] \n",
      "\n",
      "[0.   0.75] [0.   0.75] [0.   0.75] [1 4] \n",
      "\n",
      "[0.25 0.  ] [0.5 0. ] [0.33333333 0.        ] [2 3] \n",
      "\n",
      "[0.4 0. ] [1. 0.] [0.57142857 0.        ] [2 3] \n",
      "\n",
      "[0.5 0. ] [0.25 0.  ] [0.33333333 0.        ] [4 1] \n",
      "\n",
      "[0.  0.5] [0.         0.66666667] [0.         0.57142857] [2 3] \n",
      "\n",
      "[0. 0.] [0. 0.] [0. 0.] [2. 3.] \n",
      "\n",
      "[0.  0.6] [0. 1.] [0.   0.75] [2 3] \n",
      "\n",
      "[0.5 0. ] [0.66666667 0.        ] [0.57142857 0.        ] [3 2] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def crossValidate(data, attributes, numOfNeighbors, numOfTests, target='disease', level = 10):\n",
    "    folds = []\n",
    "    for i in range(level):\n",
    "        folds.append(data.sample(frac = 1/level))\n",
    "        \n",
    "    # Train missing one fold\n",
    "    for i in range(level-1):\n",
    "        temp = pd.concat([data,folds[i]])\n",
    "        temp = temp.drop_duplicates(keep=False)\n",
    "        \n",
    "        y_pred,y_true = testMeSenpai(temp, attributes, numOfNeighbors, numOfTests, target='disease')\n",
    "        (p,r,f,s) = precision_recall_fscore_support(y_pred,y_true,zero_division=0)\n",
    "        print(p,r,f,s,'\\n')\n",
    "        \n",
    "df1 = df.copy()\n",
    "k = 5\n",
    "numOfTests = 5\n",
    "attributes = ['age','trestbps']\n",
    "\n",
    "crossValidate(df1,attributes,k,numOfTests)\n",
    "# y_pred, y_true = testMeSenpai(df1,attributes,k,numOfTests)\n",
    "# (p,r,f,s) = precision_recall_fscore_support(y_pred,y_true)\n",
    "# display(p,r,f,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testAgainstTest(testData,attributes,k):\n",
    "    y_pred, y_true = testMeSenpai(testData,attributes,k)\n",
    "    (p,r,f,s) = precision_recall_fscore_support(y_pred,y_true)\n",
    "    return p,r,f,s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is the value of k (nearest neigbors) and set of attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day of the challenge set, all we need to do is change this file name and run it\n",
    "new_df = pd.read_csv('cleveland-test-sample.csv')\n",
    "\n",
    "# Collapse all values 1-4 into a single value so that \"num\" is boolean\n",
    "new_df = new_df.rename({'num':'disease','Unnamed: 0':'id'}, axis=1)\n",
    "new_df['disease'] = new_df.disease.apply(lambda x: min(x, 1))\n",
    "\n",
    "# Build a bigger data set to \n",
    "temp = pd.concat([df,new_df]).reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chosen features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_features = ['cp', 'trestbps', 'chol', 'restecg', 'thalach', 'exang', 'thal', 'age']\n",
    "numFeatures = 5\n",
    "attributes = ['age','trestbps','chol', 'thalach']\n",
    "# standardizing noncatagorical data\n",
    "newAttributes = []\n",
    "data1 = df.copy()\n",
    "for attribute in attributes:\n",
    "    standard = (data1[attribute]-data1[attribute].mean())/data1[attribute].std()\n",
    "    chosen_features.remove(standard.name)\n",
    "    chosen_features.append(standard.name+'_s')\n",
    "    standard.name = standard.name+'_s'\n",
    "    newAttributes.append(standard.name)\n",
    "    data1 = pd.concat([data1,standard],axis=1)\n",
    "    data1.drop(attribute,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makefeaturesList(chosen_features, n):\n",
    "    featureslist = list(itertools.combinations(chosen_features,n)) #\n",
    "    featureslist = [list(x) for x in featureslist]\n",
    "    return featureslist\n",
    "# data 1 is processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## monte carlo data split with selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make random split for one monte carlo cross validation run\n",
    "def monteCarloCVSplit(data : pd.DataFrame , level = 10):\n",
    "    CVtest = data.sample(frac = 1/level)\n",
    "    CVtrain = data.drop(CVtest.index)\n",
    "    return CVtrain, CVtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run knn on given attributes and CV split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knnPredictions(CVtrain, CVTest, attributes, k, target='disease'):\n",
    "    nn = NearestNeighbors(n_neighbors=k , metric='euclidean', algorithm='auto')\n",
    "    \n",
    "    # Build underlying structure with standardized data   \n",
    "    X = CVtrain[attributes].values\n",
    "    y = CVtrain[target].values\n",
    "    \n",
    "    testX = CVTest[attributes].values\n",
    "    testy = CVTest[target].values\n",
    "    fit = nn.fit(X) # fits training data to model\n",
    "    \n",
    "    # nbrs = neighbors\n",
    "    #this fit finds the nearest neigbors from the training set to the test set \n",
    "    distances, nbrs = fit.kneighbors(testX, n_neighbors = k) \n",
    "    \n",
    "    # Count the number of neighbors that have target\n",
    "\n",
    "    diseasdedNbrCount = []\n",
    "    for nbrList in nbrs:\n",
    "        diseasdedNbrCount.append([1 if y[nbr] == 1 else 0 for nbr in nbrList])\n",
    "    \n",
    "    predictions = []\n",
    "    for l in diseasdedNbrCount:\n",
    "        numOfDiseased = sum(l)\n",
    "        if numOfDiseased > k/2:\n",
    "            predictions.append(1)\n",
    "        else:\n",
    "            predictions.append(0)\n",
    "    # print(predictions,'\\n',diseasdedNbrCount)\n",
    "    return predictions , testy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make combinations of up to 8 attriubutes\n",
    "def getBestknn(data, chosen_features, numOfNeighbors = 7,target='disease'):\n",
    "    bestModel= [0,[]]\n",
    "    for i in range(8):\n",
    "        featuresList = makefeaturesList(chosen_features,i+1)\n",
    "        # for each combination of size i\n",
    "        for j in range(len(featuresList)):\n",
    "            # Do monte carlo validation 10 times\n",
    "            pSum = 0\n",
    "            rSum = 0\n",
    "            f1Sum = 0\n",
    "            for k in range(10):\n",
    "                CVtrain1, CVtest1 = monteCarloCVSplit(data)\n",
    "                #train model and report scores    \n",
    "                preds, actuals = knnPredictions(CVtrain1, CVtest1, featuresList[j] , numOfNeighbors,target=target)\n",
    "                (p,r,f,s) = precision_recall_fscore_support(preds,actuals,zero_division=0,average='binary')\n",
    "                f1 = (p*r)/(p + r)\n",
    "                pSum += p\n",
    "                rSum += r\n",
    "                f1Sum += f1\n",
    "            avgP = pSum/10\n",
    "            avgR = rSum/10\n",
    "            avgF1 = f1Sum/10\n",
    "            # Update our best model\n",
    "            if avgF1 > bestModel[0]:\n",
    "                bestModel = [avgF1,featuresList[j],avgP,avgR]\n",
    "    return bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob\\AppData\\Local\\Temp\\ipykernel_25360\\1623743665.py:17: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  f1 = (p*r)/(p + r)\n",
      "C:\\Users\\Jacob\\AppData\\Local\\Temp\\ipykernel_25360\\1623743665.py:17: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  f1 = (p*r)/(p + r)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4030991311426094, ['cp', 'restecg', 'exang', 'thal', 'chol_s', 'thalach_s'], 0.8206318681318683, 0.8042586580086579]\n"
     ]
    }
   ],
   "source": [
    "print(getBestknn(data1,chosen_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind_Speed</th>\n",
       "      <th>general_diffuse_flows</th>\n",
       "      <th>diffuse flows</th>\n",
       "      <th>Zone_1_Power</th>\n",
       "      <th>Zone_2_Power</th>\n",
       "      <th>Zone_3_Power</th>\n",
       "      <th>highPowerUse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2017 0:00</td>\n",
       "      <td>6.559</td>\n",
       "      <td>73.8</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.119</td>\n",
       "      <td>34055.69620</td>\n",
       "      <td>16128.87538</td>\n",
       "      <td>20240.96386</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/1/2017 0:10</td>\n",
       "      <td>6.414</td>\n",
       "      <td>74.5</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.085</td>\n",
       "      <td>29814.68354</td>\n",
       "      <td>19375.07599</td>\n",
       "      <td>20131.08434</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/1/2017 0:20</td>\n",
       "      <td>6.313</td>\n",
       "      <td>74.5</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.100</td>\n",
       "      <td>29128.10127</td>\n",
       "      <td>19006.68693</td>\n",
       "      <td>19668.43373</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1/2017 0:30</td>\n",
       "      <td>6.121</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.096</td>\n",
       "      <td>28228.86076</td>\n",
       "      <td>18361.09422</td>\n",
       "      <td>18899.27711</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/2017 0:40</td>\n",
       "      <td>5.921</td>\n",
       "      <td>75.7</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.085</td>\n",
       "      <td>27335.69620</td>\n",
       "      <td>17872.34043</td>\n",
       "      <td>18442.40964</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52411</th>\n",
       "      <td>12/30/2017 23:10</td>\n",
       "      <td>7.010</td>\n",
       "      <td>72.4</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.096</td>\n",
       "      <td>31160.45627</td>\n",
       "      <td>26857.31820</td>\n",
       "      <td>14780.31212</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52412</th>\n",
       "      <td>12/30/2017 23:20</td>\n",
       "      <td>6.947</td>\n",
       "      <td>72.6</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.093</td>\n",
       "      <td>30430.41825</td>\n",
       "      <td>26124.57809</td>\n",
       "      <td>14428.81152</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52413</th>\n",
       "      <td>12/30/2017 23:30</td>\n",
       "      <td>6.900</td>\n",
       "      <td>72.8</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.074</td>\n",
       "      <td>29590.87452</td>\n",
       "      <td>25277.69254</td>\n",
       "      <td>13806.48259</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52414</th>\n",
       "      <td>12/30/2017 23:40</td>\n",
       "      <td>6.758</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.089</td>\n",
       "      <td>28958.17490</td>\n",
       "      <td>24692.23688</td>\n",
       "      <td>13512.60504</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52415</th>\n",
       "      <td>12/30/2017 23:50</td>\n",
       "      <td>6.580</td>\n",
       "      <td>74.1</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.111</td>\n",
       "      <td>28349.80989</td>\n",
       "      <td>24055.23167</td>\n",
       "      <td>13345.49820</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52416 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               DateTime  Temperature  Humidity  Wind_Speed  \\\n",
       "0         1/1/2017 0:00        6.559      73.8       0.083   \n",
       "1         1/1/2017 0:10        6.414      74.5       0.083   \n",
       "2         1/1/2017 0:20        6.313      74.5       0.080   \n",
       "3         1/1/2017 0:30        6.121      75.0       0.083   \n",
       "4         1/1/2017 0:40        5.921      75.7       0.081   \n",
       "...                 ...          ...       ...         ...   \n",
       "52411  12/30/2017 23:10        7.010      72.4       0.080   \n",
       "52412  12/30/2017 23:20        6.947      72.6       0.082   \n",
       "52413  12/30/2017 23:30        6.900      72.8       0.086   \n",
       "52414  12/30/2017 23:40        6.758      73.0       0.080   \n",
       "52415  12/30/2017 23:50        6.580      74.1       0.081   \n",
       "\n",
       "       general_diffuse_flows  diffuse flows  Zone_1_Power  Zone_2_Power  \\\n",
       "0                      0.051          0.119   34055.69620   16128.87538   \n",
       "1                      0.070          0.085   29814.68354   19375.07599   \n",
       "2                      0.062          0.100   29128.10127   19006.68693   \n",
       "3                      0.091          0.096   28228.86076   18361.09422   \n",
       "4                      0.048          0.085   27335.69620   17872.34043   \n",
       "...                      ...            ...           ...           ...   \n",
       "52411                  0.040          0.096   31160.45627   26857.31820   \n",
       "52412                  0.051          0.093   30430.41825   26124.57809   \n",
       "52413                  0.084          0.074   29590.87452   25277.69254   \n",
       "52414                  0.066          0.089   28958.17490   24692.23688   \n",
       "52415                  0.062          0.111   28349.80989   24055.23167   \n",
       "\n",
       "       Zone_3_Power  highPowerUse  \n",
       "0       20240.96386          True  \n",
       "1       20131.08434         False  \n",
       "2       19668.43373         False  \n",
       "3       18899.27711         False  \n",
       "4       18442.40964         False  \n",
       "...             ...           ...  \n",
       "52411   14780.31212         False  \n",
       "52412   14428.81152         False  \n",
       "52413   13806.48259         False  \n",
       "52414   13512.60504         False  \n",
       "52415   13345.49820         False  \n",
       "\n",
       "[52416 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power = pd.read_csv('city_power_consumption.csv')\n",
    "power = power.rename(columns={'Zone 1 Power Consumption':'Zone_1_Power',\n",
    "                            'Zone 2  Power Consumption':'Zone_2_Power',\n",
    "                            'Zone 3  Power Consumption':'Zone_3_Power',\n",
    "                            'general diffuse flows':'general_diffuse_flows',\n",
    "                            'Wind Speed':'Wind_Speed' })\n",
    "powerMean = power['Zone_1_Power'].mean()\n",
    "power['highPowerUse'] = power.Zone_1_Power>powerMean\n",
    "power\n",
    "# power.plot(power['Temperature'])\n",
    "# sns.lineplot(data = power, x = 'Temperature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43279497419150514, ['Humidity', 'general_diffuse_flows', 'Zone_2_Power', 'Zone_3_Power_s_s_s'], 0.8993935386231702, 0.8342825093492368]\n"
     ]
    }
   ],
   "source": [
    "chosen_features = ['Temperature','Humidity','Wind_Speed', 'general_diffuse_flows', 'diffuse flows','Zone_2_Power','Zone_3_Power']\n",
    "numFeatures = 4\n",
    "# standardizing noncatagorical data\n",
    "newAttributes = []\n",
    "stdData = power.copy()\n",
    "for attribute in chosen_features:\n",
    "    standard = (stdData[attribute]-stdData[attribute].mean())/stdData[attribute].std()\n",
    "    chosen_features.remove(standard.name)\n",
    "    chosen_features.append(standard.name+'_s')\n",
    "    standard.name = standard.name+'_s'\n",
    "    newAttributes.append(standard.name)\n",
    "    stdData = pd.concat([stdData,standard],axis=1)\n",
    "    stdData.drop(attribute,axis=1,inplace=True)\n",
    "print(getBestknn(stdData,chosen_features,numOfNeighbors = 100,target='highPowerUse'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = power.sample(frac=.01), x = 'Temperature', y = 'Zone_1_Power')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = power.sample(frac=.01), x = 'Humidity', y = 'Zone_1_Power')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day of the challenge set, all we need to do is change this file name and run it\n",
    "new_df = pd.read_csv('cleveland-test-sample.csv')\n",
    "\n",
    "# Collapse all values 1-4 into a single value so that \"num\" is boolean\n",
    "new_df = new_df.rename({'num':'disease','Unnamed: 0':'id'}, axis=1)\n",
    "new_df['disease'] = new_df.disease.apply(lambda x: min(x, 1))\n",
    "\n",
    "# Build a bigger data set to \n",
    "temp = pd.concat([df,new_df]).reset_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8112dd241fa2daf28d9e3e7428f74cc036918cdd417492de7d9a77b623e05e74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
